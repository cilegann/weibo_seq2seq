{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Thu Oct 12 12:04:31 2017\n",
    "\n",
    "@author: gama\n",
    "\"\"\"\n",
    "from  keras.utils import multi_gpu_model\n",
    "import tensorflow as tf\n",
    "import re\n",
    "import numpy as np\n",
    "from keras.models import Model\n",
    "from keras.layers import Embedding,Masking\n",
    "from keras.layers import Input, Dense,Reshape,concatenate,Flatten,Activation,Permute,multiply\n",
    "from keras.layers import GRU,Conv1D,GlobalMaxPooling1D,TimeDistributed,RepeatVector,LSTM,MaxPooling1D\n",
    "from keras import optimizers\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.layers import Lambda,Dropout\n",
    "from keras.utils import to_categorical,multi_gpu_model\n",
    "import gc\n",
    "import random\n",
    "import nltk\n",
    "import math\n",
    "from tqdm import tqdm,tqdm_notebook\n",
    "import csv\n",
    "import keras.backend as K\n",
    "from keras.models import load_model\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#setting tf_config\n",
    "gpu_options = tf.GPUOptions(allow_growth=True)\n",
    "sess = tf.Session(config=tf.ConfigProto(gpu_options=gpu_options,allow_soft_placement=True))\n",
    "K.set_session(sess)\n",
    "# jieba.load_userdict('dict.txt.big.txt')\n",
    "# jieba.load_userdict('NameDict_Ch_v2.txt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "post=[]\n",
    "response=[]\n",
    "post_file=open('./stc_weibo_train_post','r')\n",
    "for i in post_file.readlines():\n",
    "    post.append(i.split())\n",
    "\n",
    "post_file=open('./stc_weibo_train_response','r')\n",
    "for i in post_file.readlines():\n",
    "    response.append(i.split())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4435964 4435959\n"
     ]
    }
   ],
   "source": [
    "print(len(post),len(response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_trainable(net, val):\n",
    "    net.trainable = val\n",
    "    for l in net.layers:\n",
    "        l.trainable = val\n",
    "token_stream = []\n",
    "que_pad=20\n",
    "ans_pad=10\n",
    "stop_count=0\n",
    "pair_train1=[]\n",
    "pair_train2=[]\n",
    "check_stop=[]\n",
    "count=0\n",
    "\n",
    "for key,i in enumerate(post):\n",
    "    if len(pair_train1)>=100000:\n",
    "        break\n",
    "    if len(i)>=ans_pad or len(response[key])>=ans_pad or len(i)<3 or len(response[key])<3:\n",
    "        continue\n",
    "    while len(i)<que_pad:\n",
    "        i.append('PAD')\n",
    "    while len(response[key])<ans_pad:\n",
    "        response[key].append('PAD')    \n",
    "    token_stream.extend(i)\n",
    "    pair_train1.append(i)    \n",
    "    token_stream.extend(response[key])\n",
    "    pair_train2.append(response[key])    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_of_pairs 100000\n",
      "num_words:\n",
      "75571\n",
      "process_data\n"
     ]
    }
   ],
   "source": [
    "print('num_of_pairs',len(pair_train1))\n",
    "pair=len(pair_train1)\n",
    "#TOP=['PAD','EOS']             \n",
    "#TOP.extend(token_stream)\n",
    "words=list(set(token_stream))\n",
    "words.remove('PAD')\n",
    "#del token_stream\n",
    "\n",
    "word2idx={}\n",
    "word2idx['PAD']=0\n",
    "for i, word in enumerate(words):\n",
    "    word2idx[word]=i+1\n",
    "num_words = len(word2idx)\n",
    "print(\"num_words:\")\n",
    "print(num_words)\n",
    "                    \n",
    "print('process_data')\n",
    "\n",
    "predict_pair=ans_pad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(pair_train1)):\n",
    "    for j in range(que_pad):\n",
    "        pair_train1[i][j]=word2idx[pair_train1[i][j]]\n",
    "\n",
    "for i in range(len(pair_train2)):\n",
    "    for j in range(ans_pad):\n",
    "        pair_train2[i][j]=word2idx[pair_train2[i][j]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x=[]\n",
    "train_y=[]\n",
    "pad_sequence=[word2idx['PAD']]*ans_pad\n",
    "for i in range(len(pair_train1)):\n",
    "    for j in range(ans_pad):\n",
    "        forward=pair_train1[i][:ans_pad]\n",
    "        backward=pad_sequence[j:ans_pad]\n",
    "        #print(backward)\n",
    "        train_x.append(forward+backward+pair_train2[i][:j]) \n",
    "        train_y.append([pair_train2[i][j]])\n",
    "\n",
    " \n",
    "train_x=np.array(train_x)\n",
    "train_y=np.array(train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000000, 20)\n",
      "(1000000, 1)\n"
     ]
    }
   ],
   "source": [
    "print(train_x.shape)\n",
    "print(train_y.shape)\n",
    "def get_model():\n",
    "    dim=256\n",
    "    inputs = Input(shape=(que_pad,))\n",
    "    g_emb=Embedding(num_words+1,dim,mask_zero=True, input_length=(que_pad))(inputs)\n",
    "    decoder = GRU(dim)(g_emb)\n",
    "    decoder = Dense(num_words,activation=\"softmax\")(decoder)\n",
    "    model = Model(inputs=inputs , outputs=decoder)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ppx(y_true, y_pred):\n",
    "     loss = K.sparse_categorical_crossentropy(y_true, y_pred)\n",
    "     perplexity = K.cast(K.pow(math.e, K.mean(loss, axis=-1)), K.floatx())\n",
    "     return perplexity\n",
    "   \n",
    "\n",
    "g_model=get_model()\n",
    "#sampling_model= multi_gpu_model(get_model(), gpus=2)\n",
    "g_model.compile(loss=ppx, optimizer='adam',metrics=['accuracy'])\n",
    "earlyStopping=EarlyStopping(monitor='loss', patience=2, verbose=2, mode='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 800000 samples, validate on 200000 samples\n",
      "Epoch 1/49\n",
      "800000/800000 [==============================] - 118s 148us/step - loss: 1112.5352 - acc: 0.9972 - val_loss: 444.9644 - val_acc: 0.9996\n",
      "Epoch 2/49\n",
      "800000/800000 [==============================] - 115s 144us/step - loss: 314.3999 - acc: 0.5809 - val_loss: 329.7462 - val_acc: 0.3770\n",
      "Epoch 3/49\n",
      "800000/800000 [==============================] - 115s 144us/step - loss: 222.5808 - acc: 0.3892 - val_loss: 287.4506 - val_acc: 0.3214\n",
      "Epoch 4/49\n",
      "800000/800000 [==============================] - 116s 145us/step - loss: 170.1783 - acc: 0.3443 - val_loss: 264.1064 - val_acc: 0.2929\n",
      "Epoch 5/49\n",
      "800000/800000 [==============================] - 116s 144us/step - loss: 131.1400 - acc: 0.3193 - val_loss: 285.2011 - val_acc: 0.2435\n",
      "Epoch 6/49\n",
      "800000/800000 [==============================] - 116s 145us/step - loss: 98.5297 - acc: 0.3075 - val_loss: 270.0126 - val_acc: 0.2704\n",
      "Epoch 7/49\n",
      "800000/800000 [==============================] - 116s 145us/step - loss: 70.2675 - acc: 0.2996 - val_loss: 310.9560 - val_acc: 0.2487\n",
      "Epoch 8/49\n",
      "800000/800000 [==============================] - 116s 145us/step - loss: 48.6282 - acc: 0.2945 - val_loss: 342.5910 - val_acc: 0.2472\n",
      "Epoch 9/49\n",
      "800000/800000 [==============================] - 116s 145us/step - loss: 34.2034 - acc: 0.2907 - val_loss: 423.1739 - val_acc: 0.2208\n",
      "Epoch 10/49\n",
      "800000/800000 [==============================] - 116s 145us/step - loss: 25.4345 - acc: 0.2875 - val_loss: 493.1686 - val_acc: 0.2161\n",
      "Epoch 11/49\n",
      "800000/800000 [==============================] - 116s 145us/step - loss: 20.0896 - acc: 0.2852 - val_loss: 516.4567 - val_acc: 0.2263\n",
      "Epoch 12/49\n",
      "800000/800000 [==============================] - 116s 145us/step - loss: 16.3489 - acc: 0.2830 - val_loss: 597.7689 - val_acc: 0.2209\n",
      "Epoch 13/49\n",
      "800000/800000 [==============================] - 116s 145us/step - loss: 13.6095 - acc: 0.2812 - val_loss: 669.2806 - val_acc: 0.2223\n",
      "Epoch 14/49\n",
      "800000/800000 [==============================] - 116s 145us/step - loss: 11.5333 - acc: 0.2798 - val_loss: 822.7307 - val_acc: 0.2004\n",
      "Epoch 15/49\n",
      "800000/800000 [==============================] - 116s 144us/step - loss: 9.9281 - acc: 0.2784 - val_loss: 871.6127 - val_acc: 0.2128\n",
      "Epoch 16/49\n",
      "800000/800000 [==============================] - 116s 145us/step - loss: 8.6768 - acc: 0.2774 - val_loss: 1013.2545 - val_acc: 0.2029\n",
      "Epoch 17/49\n",
      "800000/800000 [==============================] - 116s 145us/step - loss: 7.6752 - acc: 0.2764 - val_loss: 1151.1656 - val_acc: 0.2000\n",
      "Epoch 18/49\n",
      "800000/800000 [==============================] - 116s 145us/step - loss: 6.8704 - acc: 0.2756 - val_loss: 1248.3673 - val_acc: 0.2049\n",
      "Epoch 19/49\n",
      "800000/800000 [==============================] - 116s 145us/step - loss: 6.2044 - acc: 0.2750 - val_loss: 1429.0732 - val_acc: 0.1995\n",
      "Epoch 20/49\n",
      "800000/800000 [==============================] - 116s 145us/step - loss: 5.6767 - acc: 0.2743 - val_loss: 1643.8184 - val_acc: 0.1924\n",
      "Epoch 21/49\n",
      "726528/800000 [==========================>...] - ETA: 9s - loss: 5.1361 - acc: 0.2732"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-7c81c5ad835c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mg_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_x\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m49\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m512\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mearlyStopping\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "g_model.fit(train_x,train_y, epochs=49, batch_size=512,validation_split=0.2,verbose=1,callbacks=[earlyStopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_model=g_model #prepare assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "question\n",
      "你家里有山寨充电器么？PADPADPADPADPADPADPADPADPADPADPADPADPAD还是觉得他像大号孙继海PADPADPADPAD\n",
      "RAP_model\n",
      "是啊，看起来像个左撇PADPAD\n",
      "question\n",
      "我国新闻队伍完全可以信赖！PADPADPADPADPADPADPADPADPADPADPADPADPAD子欲孝而亲不在！PADPAD\n",
      "RAP_model\n",
      "李开复老师苍井空老师PADPADPADPADPADPAD\n",
      "question\n",
      "第一书记大，还是总书记大？PADPADPADPADPADPADPADPADPADPADPADPAD勤奋严谨，团结进取PADPADPADPADPAD\n",
      "RAP_model\n",
      "我现在看到了我的我。PADPAD\n",
      "question\n",
      "当你的宠物爱上了看电视。PADPADPADPADPADPADPADPADPADPADPAD为什么要给他立像？PADPADPADPAD\n",
      "RAP_model\n",
      "因为你的官水哇？PADPADPAD\n",
      "question\n",
      "妈，给我点钱！alinkPADPADPADPADPADPADPADPADPADPADPADPADPAD姑姑手工做的包子。PADPADPADPAD\n",
      "RAP_model\n",
      "姑姑手工做的很好。PADPADPAD\n"
     ]
    }
   ],
   "source": [
    "def output_sequence(pair_train1,pair_train2,num,g_model):\n",
    "    word2=[]\n",
    "    test=[pair_train1[num]]\n",
    "    #print(test)\n",
    "    test=np.array(test)\n",
    "    index=g_model.predict(test)\n",
    "    index=np.argmax(index[0],axis=-1)      \n",
    "    word2.append(index)\n",
    "    for i in range(ans_pad-1):\n",
    "        test=np.delete(test,ans_pad,1)\n",
    "        test=np.concatenate([test,[[index]]],axis=1)\n",
    "        index=g_model.predict(test)\n",
    "        index=np.argmax(index[0],axis=-1)\n",
    "        word2.append(index)\n",
    "        if str(index) == str(word2idx['EOS']):\n",
    "              break\n",
    "    que=[]\n",
    "    sample=[]\n",
    "    test=[pair_train1[num]+pair_train2[num]]\n",
    "    for g in test[0]:\n",
    "          for value, age in word2idx.items():\n",
    "                if age == g:\n",
    "                \tque.append(value)\n",
    "    for g in word2:\n",
    "          for value, age in word2idx.items():\n",
    "                if age == g:\n",
    "                \tsample.append(value)\n",
    "    print('question')\n",
    "    print(''.join(que))\n",
    "    print('RAP_model') \n",
    "    print(''.join(sample))\n",
    "    que=que[0:20]+['   ans:   ']+que[ans_pad:]      \n",
    "    return  ''.join(que),''.join(sample)\n",
    "update_g=len(pair_train1)\n",
    "for i in range(5):\n",
    "    output_sequence(pair_train1,pair_train2,random.randint(0,random.randint(0,pair-1)),g_model)\n",
    "\n",
    "old_result=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim=128\n",
    "d_input1=Input(shape=(que_pad,))\n",
    "d_input2=Input(shape=(1,))\n",
    "#,mask_zero=True\n",
    "con=concatenate([d_input1,d_input2],axis=1)\n",
    "d_emb=Embedding(num_words+1,dim, input_length=(que_pad+1))(con)\n",
    "sent_representation=LSTM(dim)(d_emb)\n",
    "#sent_representation=GlobalMaxPooling1D()(cnn)\n",
    "probabilities = Dense(2, activation='softmax')(sent_representation)\n",
    "discriminator = Model([d_input1,d_input2] , probabilities)\n",
    "discriminator.compile(optimizer='adam',loss=\"categorical_crossentropy\",metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distribution_index(fake):\n",
    "    fake_idx=[]\n",
    "    for i in fake:\n",
    "    \tw=np.argmax(i)\n",
    "    \tfake_idx.append([w])\n",
    "    fake_idx=np.array(fake_idx)\n",
    "    return fake_idx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rollout_reward(train_x,train_y,count,candidate):\n",
    "    rollout_sample=[]\n",
    "    new_input=np.array(train_x)\n",
    "    #print(new_input.shape)\n",
    "    new_x=[]\n",
    "    new_y=[]\n",
    "    new_input_x=[]\n",
    "    new_input_y=[]\n",
    "    reward=[]\n",
    "    \n",
    "    for i in range(count):\n",
    "        fake=g_model.predict(new_input)\n",
    "        old_input=new_input\n",
    "        new_input=[]\n",
    "        for k in range(len(fake)):\n",
    "            #print(k)\n",
    "            index=np.argsort(fake[k])\n",
    "            index=index[::-1]#排序由機率大到小\n",
    "            for key,j in enumerate(index[0:candidate]):\n",
    "                if i==0:\n",
    "                    new_input_x.append(train_x[0])\n",
    "                    new_input_y.append([j])\n",
    "                new_x.append(new_input)\n",
    "                new_y.append([j])\n",
    "                con=np.delete(old_input[k],ans_pad,0)\n",
    "                con=np.concatenate([con,[j]],axis=0)\n",
    "                new_input.append(con)\n",
    "                \n",
    "        new_input=np.array(new_input)\n",
    "        \n",
    "    new_y=np.array(new_y)\n",
    "    #print(new_input,new_y) \n",
    "    k=len(new_input)//candidate\n",
    "    for i in range(candidate):\n",
    "        vector=discriminator.predict([new_input[k*i:k*(i+1)],\n",
    "                                  new_y[k*i:k*(i+1)]])[:,0]\n",
    "        reward.append(np.mean(vector))\n",
    "#     reward.append(discriminator.predict([train_x,train_y])[0][0])\n",
    "    #print(reward)\n",
    "    reward=reward-np.mean(reward)\n",
    "#     new_input_x.append(train_x[0])\n",
    "#     new_input_y.append(train_y[0])\n",
    "    return new_input_x,new_input_y,reward.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def greedy_search(g_model,train_x,train_y):\n",
    "    new_trainX=[]\n",
    "    new_trainY=[]\n",
    "    for key,i in enumerate(tqdm_notebook(train_x)):\n",
    "        if key%ans_pad==0:\n",
    "            train_w=i\n",
    "        else:\n",
    "            #train_w[ans_pad+key%ans_pad-1]=index\n",
    "            train_w=np.delete(train_w,ans_pad,0)   \n",
    "            train_w=np.concatenate([train_w,[index]],axis=0)    \n",
    "        index=g_model.predict(np.array([train_w]))\n",
    "        index=np.argmax(index[0],axis=-1)\n",
    "        new_trainX.append(train_w)    \n",
    "        new_trainY.append([index])\n",
    "    new_trainX=np.array(new_trainX)\n",
    "    new_trainY=np.array(new_trainY)\n",
    "    return new_trainX,new_trainY\n",
    "def train_d(discriminator,train_x,train_y,X,Y):\n",
    "    earlyStopping=EarlyStopping(monitor='loss', patience=1, verbose=2, mode='auto')\n",
    "    n = len(train_x)\n",
    "    YT = np.zeros([n*2,2])\n",
    "    YT[0:n,1] = 1\n",
    "    YT[n:,0] = 1\n",
    "    #fake=distribution_index(fake)\n",
    "    XT=np.concatenate([X,train_x])\n",
    "    XT2=np.concatenate([Y,train_y])\n",
    "    result=discriminator.fit([XT,XT2],YT, epochs=1,shuffle=True, batch_size=32, verbose=0,callbacks=[earlyStopping])\n",
    "    return result.history['acc'][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_all_mean(train_x,train_y):\n",
    "    fake=g_model.predict(train_x)\n",
    "    #per=s_model.evaluate(train_x,train_y,batch_size=512)\n",
    "\n",
    "    #per=1/per[0]\n",
    "    mean=discriminator.predict([train_x,distribution_index(fake)])\n",
    "    return np.mean(mean[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch=0\n",
    "#for s in range(120):\n",
    "for x in range(10):\n",
    "#     print(\"greedy-search\")\n",
    "#     X,Y=greedy_search(g_model,train_x[::ans_pad],train_y[::ans_pad])\n",
    "#     print('d-step')\n",
    "#     result=train_d(discriminator,train_x[::ans_pad],train_y[::ans_pad],X,Y)\n",
    "#     del X,Y\n",
    "#     print(result)\n",
    "\n",
    "#     print('finishsearch')\n",
    "    count=0   \n",
    "    dis_x=[]\n",
    "    dis_y=[]\n",
    "    reward=[]\n",
    "    for g in tqdm_notebook(range(int(len(train_x)))):\n",
    "        if g%ans_pad==0:\n",
    "             code=0\n",
    "        new_trainX=[]\n",
    "        new_trainY=[]\n",
    "        if g%ans_pad==0:\n",
    "            train_w=train_x[g]    \n",
    "        index=g_model.predict(np.array([train_w]))\n",
    "        index=np.argmax(index[0],axis=-1)\n",
    "        new_trainX.append(train_w)    \n",
    "        new_trainY.append([index])\n",
    "        if g%ans_pad!=0:\n",
    "            train_w=np.delete(train_w,ans_pad,0)   \n",
    "            train_w=np.concatenate([train_w,[index]],axis=0)\n",
    "        s=rollout_reward(new_trainX,new_trainY,(ans_pad-g%ans_pad),2)    \n",
    "        dis_x.extend(s[0])\n",
    "        dis_y.extend(s[1]) \n",
    "        reward.extend(s[2])\n",
    "        code+=1 \n",
    "        if g%10000==0 and g!=0:\n",
    "            print('batch',g)\n",
    "            g_model.fit(np.array(dis_x),np.array(dis_y),epochs=1,batch_size=256,sample_weight=np.array(reward),verbose=0)\n",
    "            dis_x=[]\n",
    "            dis_y=[]\n",
    "            reward=[]\n",
    "            for i in range(3):\n",
    "                output_sequence(pair_train1,pair_train2,random.randint(0,random.randint(0,pair-1)),g_model)\n",
    "    epoch=epoch+1\n",
    "    print('epoch',epoch) \n",
    "    #print(\"--- %s seconds ---\" % (time.time() - start_time))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(3):\n",
    "    output_sequence(pair_train1,pair_train2,random.randint(0,random.randint(0,pair-1)),g_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "oldHeight": 369,
   "position": {
    "height": "40px",
    "left": "707px",
    "right": "70px",
    "top": "54px",
    "width": "503px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "varInspector_section_display": "none",
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
