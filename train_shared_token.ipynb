{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# coding: utf-8\n",
    "import os\n",
    "import sys\n",
    "from keras.models import Model,load_model\n",
    "from keras.layers import Input, LSTM, Dense,Activation\n",
    "from keras.layers.core import Lambda\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import keras.backend.tensorflow_backend as KTF\n",
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "post='stc_weibo_train_post'\n",
    "response='stc_weibo_train_response'\n",
    "\n",
    "batch_size=32\n",
    "sample_per_epochs=2000\n",
    "max_num_of_samples=100000\n",
    "epochs=100\n",
    "latent_dim=128\n",
    "split_word=\" \"\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '1'\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth=True\n",
    "session = tf.Session(config=config)\n",
    "KTF.set_session(session)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_texts=[]\n",
    "target_texts=[]\n",
    "token_index={}\n",
    "token_index['\\t']=0\n",
    "token_index['\\n']=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "que_len=20\n",
    "ans_len=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num of samples: 100000\n",
      "Num of unique token: 94419\n"
     ]
    }
   ],
   "source": [
    "with open(post, encoding = 'utf8') as f:\n",
    "    input_lines=f.readlines()\n",
    "with open(response, encoding = 'utf8')  as f:\n",
    "    target_lines=f.readlines()\n",
    "\n",
    "input_texts=[]\n",
    "target_texts=[]\n",
    "for i in range(len(input_lines)):\n",
    "    if len(input_texts)>=max_num_of_samples:\n",
    "        break\n",
    "    if 3<len(input_lines[i].replace(\"\\n\",\"\").split(split_word))<que_len and 3<len(target_lines[i].replace(\"\\n\",\"\").split(split_word))<ans_len-2:\n",
    "        input_texts.append(input_lines[i].replace(\"\\n\",\"\").split(split_word))\n",
    "        target_texts.append([\"\\t\"]+target_lines[i].replace(\"\\n\",\"\").split(split_word)+[\"\\n\"])\n",
    "        for word in input_texts[-1]:\n",
    "            if word not in token_index:\n",
    "                token_index[word]=len(token_index)\n",
    "        for word in target_texts[-1]:\n",
    "            if word not in token_index:\n",
    "                token_index[word]=len(token_index)\n",
    "\n",
    "num_tokens=len(token_index)\n",
    "num_samples=len(input_texts)\n",
    "print(\"Num of samples:\",num_samples )\n",
    "print(\"Num of unique token:\",num_tokens)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, None, 94419)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, None, 94419)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   [(None, 128), (None, 48408576    input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_2 (LSTM)                   [(None, None, 128),  48408576    input_2[0][0]                    \n",
      "                                                                 lstm_1[0][1]                     \n",
      "                                                                 lstm_1[0][2]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, None, 94419)  12180051    lstm_2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, None, 94419)  0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, None, 94419)  0           lambda_1[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 108,997,203\n",
      "Trainable params: 108,997,203\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "encoder_inputs=Input(shape=(None,num_tokens))\n",
    "encoder=LSTM(latent_dim,return_state=True)\n",
    "encoder_outputs,state_h,state_c=encoder(encoder_inputs)\n",
    "encoder_states=[state_h,state_c]\n",
    "\n",
    "decoder_inputs=Input(shape=(None,num_tokens))\n",
    "decoder_lstm=LSTM(latent_dim,return_sequences=True,return_state=True)\n",
    "decoder_outputs,_,_=decoder_lstm(decoder_inputs,initial_state=encoder_states)\n",
    "decoder_dense=Dense(num_tokens) #,activation='softmax'\n",
    "decoder_weighted=Lambda((lambda x: x/0.7))\n",
    "decoder_softmax=Activation('softmax')\n",
    "decoder_outputs=decoder_softmax(decoder_weighted(decoder_dense(decoder_outputs)))\n",
    "model=Model([encoder_inputs,decoder_inputs],decoder_outputs)\n",
    "model.compile(optimizer='rmsprop',loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "model.summary()\n",
    "cbes=EarlyStopping(monitor='val_loss', patience=2, verbose=0, mode='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 0 BATCH 1\n",
      "Train on 1600 samples, validate on 400 samples\n",
      "Epoch 1/1\n",
      "1600/1600 [==============================] - 46s 29ms/step - loss: 6.0169 - acc: 0.0983 - val_loss: 5.4672 - val_acc: 0.1000\n",
      "EPOCH 0 BATCH 2\n",
      "Train on 1600 samples, validate on 400 samples\n",
      "Epoch 1/1\n",
      "1600/1600 [==============================] - 42s 26ms/step - loss: 5.2583 - acc: 0.1191 - val_loss: 5.2158 - val_acc: 0.1208\n",
      "EPOCH 0 BATCH 3\n",
      "Train on 1600 samples, validate on 400 samples\n",
      "Epoch 1/1\n",
      "1600/1600 [==============================] - 42s 26ms/step - loss: 5.1309 - acc: 0.1217 - val_loss: 5.0695 - val_acc: 0.1193\n",
      "EPOCH 0 BATCH 4\n",
      "Train on 1600 samples, validate on 400 samples\n",
      "Epoch 1/1\n",
      "1600/1600 [==============================] - 42s 27ms/step - loss: 5.0592 - acc: 0.1247 - val_loss: 5.0498 - val_acc: 0.1230\n",
      "EPOCH 0 BATCH 5\n",
      "Train on 1600 samples, validate on 400 samples\n",
      "Epoch 1/1\n",
      "1600/1600 [==============================] - 42s 27ms/step - loss: 5.0335 - acc: 0.1256 - val_loss: 5.0888 - val_acc: 0.1223\n",
      "EPOCH 0 BATCH 6\n",
      "Train on 1600 samples, validate on 400 samples\n",
      "Epoch 1/1\n",
      "1600/1600 [==============================] - 42s 27ms/step - loss: 5.0054 - acc: 0.1254 - val_loss: 5.0257 - val_acc: 0.1222\n",
      "EPOCH 0 BATCH 7\n",
      "Train on 1600 samples, validate on 400 samples\n",
      "Epoch 1/1\n",
      "1600/1600 [==============================] - 42s 26ms/step - loss: 4.9832 - acc: 0.1296 - val_loss: 4.9450 - val_acc: 0.1277\n",
      "EPOCH 0 BATCH 8\n",
      "Train on 1600 samples, validate on 400 samples\n",
      "Epoch 1/1\n",
      "1600/1600 [==============================] - 42s 26ms/step - loss: 4.9611 - acc: 0.1288 - val_loss: 4.9250 - val_acc: 0.1255\n",
      "EPOCH 0 BATCH 9\n",
      "Train on 1600 samples, validate on 400 samples\n",
      "Epoch 1/1\n",
      "1600/1600 [==============================] - 42s 26ms/step - loss: 4.9183 - acc: 0.1286 - val_loss: 4.9475 - val_acc: 0.1255\n",
      "EPOCH 0 BATCH 10\n",
      "Train on 1600 samples, validate on 400 samples\n",
      "Epoch 1/1\n",
      "1600/1600 [==============================] - 42s 27ms/step - loss: 4.9275 - acc: 0.1283 - val_loss: 4.9130 - val_acc: 0.1257\n",
      "EPOCH 0 BATCH 11\n",
      "Train on 1600 samples, validate on 400 samples\n",
      "Epoch 1/1\n",
      "1600/1600 [==============================] - 42s 27ms/step - loss: 4.9398 - acc: 0.1278 - val_loss: 4.8803 - val_acc: 0.1348\n",
      "EPOCH 0 BATCH 12\n",
      "Train on 1600 samples, validate on 400 samples\n",
      "Epoch 1/1\n",
      "1600/1600 [==============================] - 42s 27ms/step - loss: 4.9083 - acc: 0.1288 - val_loss: 4.9337 - val_acc: 0.1250\n",
      "EPOCH 0 BATCH 13\n",
      "Train on 1600 samples, validate on 400 samples\n",
      "Epoch 1/1\n",
      "1600/1600 [==============================] - 42s 27ms/step - loss: 4.9188 - acc: 0.1259 - val_loss: 4.9508 - val_acc: 0.1345\n",
      "EPOCH 0 BATCH 14\n",
      "Train on 1600 samples, validate on 400 samples\n",
      "Epoch 1/1\n",
      "1600/1600 [==============================] - 42s 26ms/step - loss: 4.9246 - acc: 0.1306 - val_loss: 4.8716 - val_acc: 0.1273\n",
      "EPOCH 0 BATCH 15\n",
      "Train on 1600 samples, validate on 400 samples\n",
      "Epoch 1/1\n",
      "1600/1600 [==============================] - 42s 26ms/step - loss: 4.8952 - acc: 0.1269 - val_loss: 4.8854 - val_acc: 0.1320\n",
      "EPOCH 0 BATCH 16\n",
      "Train on 1600 samples, validate on 400 samples\n",
      "Epoch 1/1\n",
      "1600/1600 [==============================] - 42s 26ms/step - loss: 4.9104 - acc: 0.1307 - val_loss: 4.8736 - val_acc: 0.1250\n",
      "EPOCH 0 BATCH 17\n",
      "Train on 1600 samples, validate on 400 samples\n",
      "Epoch 1/1\n",
      "1600/1600 [==============================] - 42s 26ms/step - loss: 4.8806 - acc: 0.1311 - val_loss: 4.9101 - val_acc: 0.1285\n",
      "EPOCH 0 BATCH 18\n",
      "Train on 1600 samples, validate on 400 samples\n",
      "Epoch 1/1\n",
      "1600/1600 [==============================] - 42s 26ms/step - loss: 4.9051 - acc: 0.1291 - val_loss: 4.9241 - val_acc: 0.1270\n",
      "EPOCH 0 BATCH 19\n",
      "Train on 1600 samples, validate on 400 samples\n",
      "Epoch 1/1\n",
      "1600/1600 [==============================] - 42s 26ms/step - loss: 4.8934 - acc: 0.1289 - val_loss: 4.8615 - val_acc: 0.1235\n",
      "EPOCH 0 BATCH 20\n",
      "Train on 1600 samples, validate on 400 samples\n",
      "Epoch 1/1\n",
      "1600/1600 [==============================] - 42s 27ms/step - loss: 4.8723 - acc: 0.1270 - val_loss: 4.8682 - val_acc: 0.1277\n",
      "EPOCH 0 BATCH 21\n",
      "Train on 1600 samples, validate on 400 samples\n",
      "Epoch 1/1\n",
      "1600/1600 [==============================] - 42s 26ms/step - loss: 4.8288 - acc: 0.1292 - val_loss: 4.7784 - val_acc: 0.1293\n",
      "EPOCH 0 BATCH 22\n",
      "Train on 1600 samples, validate on 400 samples\n",
      "Epoch 1/1\n",
      "1600/1600 [==============================] - 42s 26ms/step - loss: 4.8315 - acc: 0.1302 - val_loss: 4.8943 - val_acc: 0.1270\n",
      "EPOCH 0 BATCH 23\n",
      "Train on 1600 samples, validate on 400 samples\n",
      "Epoch 1/1\n",
      "1600/1600 [==============================] - 42s 27ms/step - loss: 4.8609 - acc: 0.1303 - val_loss: 4.8152 - val_acc: 0.1338\n",
      "EPOCH 0 BATCH 24\n",
      "Train on 1600 samples, validate on 400 samples\n",
      "Epoch 1/1\n",
      "1600/1600 [==============================] - 42s 26ms/step - loss: 4.8578 - acc: 0.1274 - val_loss: 4.7923 - val_acc: 0.1385\n",
      "EPOCH 0 BATCH 25\n",
      "Train on 1600 samples, validate on 400 samples\n",
      "Epoch 1/1\n",
      "1600/1600 [==============================] - 42s 26ms/step - loss: 4.8343 - acc: 0.1275 - val_loss: 4.7464 - val_acc: 0.1320\n",
      "EPOCH 0 BATCH 26\n",
      "Train on 1600 samples, validate on 400 samples\n",
      "Epoch 1/1\n",
      "1600/1600 [==============================] - 42s 27ms/step - loss: 4.8422 - acc: 0.1308 - val_loss: 4.7753 - val_acc: 0.1223\n",
      "EPOCH 0 BATCH 27\n",
      "Train on 1600 samples, validate on 400 samples\n",
      "Epoch 1/1\n",
      "1600/1600 [==============================] - 42s 26ms/step - loss: 4.8381 - acc: 0.1321 - val_loss: 4.9002 - val_acc: 0.1333\n",
      "EPOCH 0 BATCH 28\n",
      "Train on 1600 samples, validate on 400 samples\n",
      "Epoch 1/1\n",
      "1600/1600 [==============================] - 42s 27ms/step - loss: 4.8100 - acc: 0.1338 - val_loss: 4.8476 - val_acc: 0.1320\n",
      "EPOCH 0 BATCH 29\n",
      "Train on 1600 samples, validate on 400 samples\n",
      "Epoch 1/1\n",
      "1600/1600 [==============================] - 42s 27ms/step - loss: 4.8390 - acc: 0.1329 - val_loss: 4.7483 - val_acc: 0.1345\n",
      "EPOCH 0 BATCH 30\n",
      "Train on 1600 samples, validate on 400 samples\n",
      "Epoch 1/1\n",
      "1600/1600 [==============================] - 42s 26ms/step - loss: 4.8009 - acc: 0.1367 - val_loss: 4.8353 - val_acc: 0.1330\n",
      "EPOCH 0 BATCH 31\n",
      "Train on 1600 samples, validate on 400 samples\n",
      "Epoch 1/1\n",
      "1600/1600 [==============================] - 42s 27ms/step - loss: 4.7967 - acc: 0.1380 - val_loss: 4.8577 - val_acc: 0.1370\n",
      "EPOCH 0 BATCH 32\n",
      "Train on 1600 samples, validate on 400 samples\n",
      "Epoch 1/1\n",
      "1600/1600 [==============================] - 42s 26ms/step - loss: 4.8052 - acc: 0.1379 - val_loss: 4.8542 - val_acc: 0.1398\n",
      "EPOCH 0 BATCH 33\n",
      "Train on 1600 samples, validate on 400 samples\n",
      "Epoch 1/1\n",
      "1600/1600 [==============================] - 42s 27ms/step - loss: 4.8076 - acc: 0.1364 - val_loss: 4.7416 - val_acc: 0.1368\n",
      "EPOCH 0 BATCH 34\n",
      "Train on 1600 samples, validate on 400 samples\n",
      "Epoch 1/1\n",
      "1600/1600 [==============================] - 42s 26ms/step - loss: 4.7584 - acc: 0.1397 - val_loss: 4.7659 - val_acc: 0.1355\n",
      "EPOCH 0 BATCH 35\n",
      "Train on 1600 samples, validate on 400 samples\n",
      "Epoch 1/1\n",
      "1600/1600 [==============================] - 42s 26ms/step - loss: 4.7997 - acc: 0.1356 - val_loss: 4.7784 - val_acc: 0.1430\n",
      "EPOCH 0 BATCH 36\n",
      "Train on 1600 samples, validate on 400 samples\n",
      "Epoch 1/1\n",
      "1600/1600 [==============================] - 42s 26ms/step - loss: 4.7830 - acc: 0.1403 - val_loss: 4.7548 - val_acc: 0.1355\n",
      "EPOCH 0 BATCH 37\n",
      "Train on 1600 samples, validate on 400 samples\n",
      "Epoch 1/1\n",
      "1600/1600 [==============================] - 42s 26ms/step - loss: 4.7777 - acc: 0.1362 - val_loss: 4.7580 - val_acc: 0.1430\n",
      "EPOCH 0 BATCH 38\n",
      "Train on 1600 samples, validate on 400 samples\n",
      "Epoch 1/1\n",
      "1600/1600 [==============================] - 42s 26ms/step - loss: 4.7776 - acc: 0.1389 - val_loss: 4.7937 - val_acc: 0.1362\n",
      "EPOCH 0 BATCH 39\n",
      "Train on 1600 samples, validate on 400 samples\n",
      "Epoch 1/1\n",
      "1600/1600 [==============================] - 42s 26ms/step - loss: 4.7858 - acc: 0.1369 - val_loss: 4.7888 - val_acc: 0.1415\n",
      "EPOCH 0 BATCH 40\n",
      "Train on 1600 samples, validate on 400 samples\n",
      "Epoch 1/1\n",
      "1600/1600 [==============================] - 42s 26ms/step - loss: 4.8090 - acc: 0.1384 - val_loss: 4.9010 - val_acc: 0.1392\n",
      "EPOCH 0 BATCH 41\n",
      "Train on 1600 samples, validate on 400 samples\n",
      "Epoch 1/1\n",
      "1600/1600 [==============================] - 42s 26ms/step - loss: 4.7755 - acc: 0.1418 - val_loss: 4.7071 - val_acc: 0.1475\n",
      "EPOCH 0 BATCH 42\n",
      "Train on 1600 samples, validate on 400 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1600/1600 [==============================] - 42s 26ms/step - loss: 4.7582 - acc: 0.1448 - val_loss: 4.8253 - val_acc: 0.1395\n",
      "EPOCH 0 BATCH 43\n",
      "Train on 1600 samples, validate on 400 samples\n",
      "Epoch 1/1\n",
      "1600/1600 [==============================] - 42s 26ms/step - loss: 4.7344 - acc: 0.1444 - val_loss: 4.7555 - val_acc: 0.1480\n",
      "EPOCH 0 BATCH 44\n",
      "Train on 1600 samples, validate on 400 samples\n",
      "Epoch 1/1\n",
      "1600/1600 [==============================] - 42s 26ms/step - loss: 4.7642 - acc: 0.1448 - val_loss: 4.7397 - val_acc: 0.1450\n",
      "EPOCH 0 BATCH 45\n",
      "Train on 1600 samples, validate on 400 samples\n",
      "Epoch 1/1\n",
      "1600/1600 [==============================] - 42s 26ms/step - loss: 4.7562 - acc: 0.1455 - val_loss: 4.6836 - val_acc: 0.1495\n",
      "EPOCH 0 BATCH 46\n",
      "Train on 1600 samples, validate on 400 samples\n",
      "Epoch 1/1\n",
      "1600/1600 [==============================] - 42s 26ms/step - loss: 4.7729 - acc: 0.1457 - val_loss: 4.7629 - val_acc: 0.1460\n",
      "EPOCH 0 BATCH 47\n",
      "Train on 1600 samples, validate on 400 samples\n",
      "Epoch 1/1\n",
      "1600/1600 [==============================] - 42s 26ms/step - loss: 4.7449 - acc: 0.1461 - val_loss: 4.7554 - val_acc: 0.1477\n",
      "EPOCH 0 BATCH 48\n",
      "Train on 1600 samples, validate on 400 samples\n",
      "Epoch 1/1\n",
      "1600/1600 [==============================] - 42s 26ms/step - loss: 4.7105 - acc: 0.1474 - val_loss: 4.6965 - val_acc: 0.1457\n",
      "EPOCH 0 BATCH 49\n",
      "Train on 1600 samples, validate on 400 samples\n",
      "Epoch 1/1\n",
      "1600/1600 [==============================] - 42s 26ms/step - loss: 4.7428 - acc: 0.1471 - val_loss: 4.6849 - val_acc: 0.1503\n",
      "EPOCH 1 BATCH 1\n",
      "Train on 1600 samples, validate on 400 samples\n",
      "Epoch 1/1\n",
      "1600/1600 [==============================] - 42s 26ms/step - loss: 4.7396 - acc: 0.1439 - val_loss: 4.8532 - val_acc: 0.1390\n",
      "EPOCH 1 BATCH 2\n",
      "Train on 1600 samples, validate on 400 samples\n",
      "Epoch 1/1\n",
      "1600/1600 [==============================] - 42s 26ms/step - loss: 4.7149 - acc: 0.1469 - val_loss: 4.7788 - val_acc: 0.1362\n",
      "EPOCH 1 BATCH 3\n",
      "Train on 1600 samples, validate on 400 samples\n",
      "Epoch 1/1\n",
      "1600/1600 [==============================] - 42s 26ms/step - loss: 4.6695 - acc: 0.1461 - val_loss: 4.7049 - val_acc: 0.1450\n",
      "EPOCH 1 BATCH 4\n",
      "Train on 1600 samples, validate on 400 samples\n",
      "Epoch 1/1\n",
      "1600/1600 [==============================] - 42s 26ms/step - loss: 4.6681 - acc: 0.1489 - val_loss: 4.7392 - val_acc: 0.1407\n",
      "EPOCH 1 BATCH 5\n",
      "Train on 1600 samples, validate on 400 samples\n",
      "Epoch 1/1\n",
      "1600/1600 [==============================] - 42s 26ms/step - loss: 4.6737 - acc: 0.1441 - val_loss: 4.8215 - val_acc: 0.1427\n",
      "EPOCH 1 BATCH 6\n",
      "Train on 1600 samples, validate on 400 samples\n",
      "Epoch 1/1\n",
      "1600/1600 [==============================] - 42s 26ms/step - loss: 4.6632 - acc: 0.1453 - val_loss: 4.7805 - val_acc: 0.1440\n",
      "EPOCH 1 BATCH 7\n",
      "Train on 1600 samples, validate on 400 samples\n",
      "Epoch 1/1\n",
      "1600/1600 [==============================] - 42s 26ms/step - loss: 4.6620 - acc: 0.1494 - val_loss: 4.7036 - val_acc: 0.1488\n",
      "EPOCH 1 BATCH 8\n",
      "Train on 1600 samples, validate on 400 samples\n",
      "Epoch 1/1\n",
      "1600/1600 [==============================] - 42s 26ms/step - loss: 4.6377 - acc: 0.1467 - val_loss: 4.7476 - val_acc: 0.1405\n",
      "EPOCH 1 BATCH 9\n",
      "Train on 1600 samples, validate on 400 samples\n",
      "Epoch 1/1\n",
      "1600/1600 [==============================] - 42s 26ms/step - loss: 4.6111 - acc: 0.1487 - val_loss: 4.7503 - val_acc: 0.1435\n",
      "EPOCH 1 BATCH 10\n",
      "Train on 1600 samples, validate on 400 samples\n",
      "Epoch 1/1\n",
      "1600/1600 [==============================] - 42s 26ms/step - loss: 4.6422 - acc: 0.1516 - val_loss: 4.7100 - val_acc: 0.1465\n",
      "EPOCH 1 BATCH 11\n",
      "Train on 1600 samples, validate on 400 samples\n",
      "Epoch 1/1\n",
      "1600/1600 [==============================] - 42s 26ms/step - loss: 4.6499 - acc: 0.1481 - val_loss: 4.7241 - val_acc: 0.1487\n",
      "EPOCH 1 BATCH 12\n",
      "Train on 1600 samples, validate on 400 samples\n",
      "Epoch 1/1\n",
      "1600/1600 [==============================] - 42s 26ms/step - loss: 4.6188 - acc: 0.1514 - val_loss: 4.7627 - val_acc: 0.1412\n",
      "EPOCH 1 BATCH 13\n",
      "Train on 1600 samples, validate on 400 samples\n",
      "Epoch 1/1\n",
      "1600/1600 [==============================] - 42s 26ms/step - loss: 4.6376 - acc: 0.1486 - val_loss: 4.7963 - val_acc: 0.1460\n",
      "EPOCH 1 BATCH 14\n",
      "Train on 1600 samples, validate on 400 samples\n",
      "Epoch 1/1\n",
      "1600/1600 [==============================] - 42s 26ms/step - loss: 4.6472 - acc: 0.1513 - val_loss: 4.7188 - val_acc: 0.1463\n",
      "EPOCH 1 BATCH 15\n",
      "Train on 1600 samples, validate on 400 samples\n",
      "Epoch 1/1\n",
      "1600/1600 [==============================] - 42s 26ms/step - loss: 4.6350 - acc: 0.1482 - val_loss: 4.7587 - val_acc: 0.1495\n",
      "EPOCH 1 BATCH 16\n",
      "Train on 1600 samples, validate on 400 samples\n",
      "Epoch 1/1\n",
      "1600/1600 [==============================] - 42s 26ms/step - loss: 4.6648 - acc: 0.1523 - val_loss: 4.7009 - val_acc: 0.1480\n",
      "EPOCH 1 BATCH 17\n",
      "Train on 1600 samples, validate on 400 samples\n",
      "Epoch 1/1\n",
      "1600/1600 [==============================] - 42s 26ms/step - loss: 4.6397 - acc: 0.1534 - val_loss: 4.7392 - val_acc: 0.1520\n",
      "EPOCH 1 BATCH 18\n",
      "Train on 1600 samples, validate on 400 samples\n",
      "Epoch 1/1\n",
      "1600/1600 [==============================] - 42s 26ms/step - loss: 4.6703 - acc: 0.1496 - val_loss: 4.7778 - val_acc: 0.1482\n",
      "EPOCH 1 BATCH 19\n",
      "Train on 1600 samples, validate on 400 samples\n",
      "Epoch 1/1\n",
      "1600/1600 [==============================] - 42s 26ms/step - loss: 4.6444 - acc: 0.1498 - val_loss: 4.7059 - val_acc: 0.1465\n",
      "EPOCH 1 BATCH 20\n",
      "Train on 1600 samples, validate on 400 samples\n",
      "Epoch 1/1\n",
      "1600/1600 [==============================] - 42s 26ms/step - loss: 4.6274 - acc: 0.1495 - val_loss: 4.7434 - val_acc: 0.1473\n",
      "EPOCH 1 BATCH 21\n",
      "Train on 1600 samples, validate on 400 samples\n",
      "Epoch 1/1\n",
      "1600/1600 [==============================] - 42s 26ms/step - loss: 4.5759 - acc: 0.1524 - val_loss: 4.6219 - val_acc: 0.1560\n",
      "EPOCH 1 BATCH 22\n",
      "Train on 1600 samples, validate on 400 samples\n",
      "Epoch 1/1\n",
      "1600/1600 [==============================] - 43s 27ms/step - loss: 4.5970 - acc: 0.1541 - val_loss: 4.7565 - val_acc: 0.1503\n",
      "EPOCH 1 BATCH 23\n",
      "Train on 1600 samples, validate on 400 samples\n",
      "Epoch 1/1\n",
      "1600/1600 [==============================] - 45s 28ms/step - loss: 4.6339 - acc: 0.1542 - val_loss: 4.6834 - val_acc: 0.1473\n",
      "EPOCH 1 BATCH 24\n",
      "Train on 1600 samples, validate on 400 samples\n",
      "Epoch 1/1\n",
      "1600/1600 [==============================] - 43s 27ms/step - loss: 4.6252 - acc: 0.1496 - val_loss: 4.6686 - val_acc: 0.1565\n",
      "EPOCH 1 BATCH 25\n",
      "Train on 1600 samples, validate on 400 samples\n",
      "Epoch 1/1\n",
      "1600/1600 [==============================] - 44s 28ms/step - loss: 4.6111 - acc: 0.1524 - val_loss: 4.6236 - val_acc: 0.1503\n",
      "EPOCH 1 BATCH 26\n",
      "Train on 1600 samples, validate on 400 samples\n",
      "Epoch 1/1\n",
      "1600/1600 [==============================] - 44s 28ms/step - loss: 4.6230 - acc: 0.1511 - val_loss: 4.6160 - val_acc: 0.1470\n",
      "EPOCH 1 BATCH 27\n",
      "Train on 1600 samples, validate on 400 samples\n",
      "Epoch 1/1\n",
      "1600/1600 [==============================] - 44s 28ms/step - loss: 4.5982 - acc: 0.1551 - val_loss: 4.7892 - val_acc: 0.1505\n",
      "EPOCH 1 BATCH 28\n",
      "Train on 1600 samples, validate on 400 samples\n",
      "Epoch 1/1\n",
      "1600/1600 [==============================] - 44s 28ms/step - loss: 4.5881 - acc: 0.1553 - val_loss: 4.7235 - val_acc: 0.1497\n",
      "EPOCH 1 BATCH 29\n",
      "Train on 1600 samples, validate on 400 samples\n",
      "Epoch 1/1\n",
      "1600/1600 [==============================] - 44s 28ms/step - loss: 4.6202 - acc: 0.1526 - val_loss: 4.6362 - val_acc: 0.1518\n",
      "EPOCH 1 BATCH 30\n",
      "Train on 1600 samples, validate on 400 samples\n",
      "Epoch 1/1\n",
      "1600/1600 [==============================] - 43s 27ms/step - loss: 4.6024 - acc: 0.1549 - val_loss: 4.7170 - val_acc: 0.1503\n",
      "EPOCH 1 BATCH 31\n",
      "Train on 1600 samples, validate on 400 samples\n",
      "Epoch 1/1\n",
      "1600/1600 [==============================] - 44s 28ms/step - loss: 4.5935 - acc: 0.1553 - val_loss: 4.7354 - val_acc: 0.1537\n",
      "EPOCH 1 BATCH 32\n",
      "Train on 1600 samples, validate on 400 samples\n",
      "Epoch 1/1\n",
      "1600/1600 [==============================] - 43s 27ms/step - loss: 4.5996 - acc: 0.1549 - val_loss: 4.7637 - val_acc: 0.1548\n",
      "EPOCH 1 BATCH 33\n",
      "Train on 1600 samples, validate on 400 samples\n",
      "Epoch 1/1\n",
      "1600/1600 [==============================] - 44s 28ms/step - loss: 4.6024 - acc: 0.1524 - val_loss: 4.6547 - val_acc: 0.1517\n",
      "EPOCH 1 BATCH 34\n",
      "Train on 1600 samples, validate on 400 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1600/1600 [==============================] - 44s 28ms/step - loss: 4.5742 - acc: 0.1547 - val_loss: 4.6368 - val_acc: 0.1588\n",
      "EPOCH 1 BATCH 35\n",
      "Train on 1600 samples, validate on 400 samples\n",
      "Epoch 1/1\n",
      "1600/1600 [==============================] - 44s 28ms/step - loss: 4.6164 - acc: 0.1520 - val_loss: 4.6669 - val_acc: 0.1605\n",
      "EPOCH 1 BATCH 36\n",
      "Train on 1600 samples, validate on 400 samples\n",
      "Epoch 1/1\n",
      "1600/1600 [==============================] - 44s 28ms/step - loss: 4.5968 - acc: 0.1567 - val_loss: 4.6460 - val_acc: 0.1550\n",
      "EPOCH 1 BATCH 37\n",
      "Train on 1600 samples, validate on 400 samples\n",
      "Epoch 1/1\n",
      "1600/1600 [==============================] - 44s 28ms/step - loss: 4.5931 - acc: 0.1512 - val_loss: 4.6835 - val_acc: 0.1523\n",
      "EPOCH 1 BATCH 38\n",
      "Train on 1600 samples, validate on 400 samples\n",
      "Epoch 1/1\n",
      "1600/1600 [==============================] - 44s 28ms/step - loss: 4.5883 - acc: 0.1544 - val_loss: 4.6800 - val_acc: 0.1545\n",
      "EPOCH 1 BATCH 39\n",
      "Train on 1600 samples, validate on 400 samples\n",
      "Epoch 1/1\n",
      "1600/1600 [==============================] - 44s 28ms/step - loss: 4.6025 - acc: 0.1556 - val_loss: 4.7077 - val_acc: 0.1537\n",
      "EPOCH 1 BATCH 40\n",
      "Train on 1600 samples, validate on 400 samples\n",
      "Epoch 1/1\n",
      "1600/1600 [==============================] - 47s 29ms/step - loss: 4.6254 - acc: 0.1549 - val_loss: 4.8015 - val_acc: 0.1470\n",
      "EPOCH 1 BATCH 41\n",
      "Train on 1600 samples, validate on 400 samples\n",
      "Epoch 1/1\n",
      "1600/1600 [==============================] - 44s 28ms/step - loss: 4.5913 - acc: 0.1571 - val_loss: 4.6148 - val_acc: 0.1563\n",
      "EPOCH 1 BATCH 42\n",
      "Train on 1600 samples, validate on 400 samples\n",
      "Epoch 1/1\n",
      "1600/1600 [==============================] - 43s 27ms/step - loss: 4.5750 - acc: 0.1576 - val_loss: 4.7657 - val_acc: 0.1510\n",
      "EPOCH 1 BATCH 43\n",
      "Train on 1600 samples, validate on 400 samples\n",
      "Epoch 1/1\n",
      "1600/1600 [==============================] - 42s 26ms/step - loss: 4.5559 - acc: 0.1592 - val_loss: 4.6934 - val_acc: 0.1630\n",
      "EPOCH 1 BATCH 44\n",
      "Train on 1600 samples, validate on 400 samples\n",
      "Epoch 1/1\n",
      "1600/1600 [==============================] - 44s 27ms/step - loss: 4.5933 - acc: 0.1600 - val_loss: 4.6761 - val_acc: 0.1527\n",
      "EPOCH 1 BATCH 45\n",
      "Train on 1600 samples, validate on 400 samples\n",
      "Epoch 1/1\n",
      "1600/1600 [==============================] - 43s 27ms/step - loss: 4.5877 - acc: 0.1579 - val_loss: 4.6182 - val_acc: 0.1570\n",
      "EPOCH 1 BATCH 46\n",
      "Train on 1600 samples, validate on 400 samples\n",
      "Epoch 1/1\n",
      "1600/1600 [==============================] - 44s 28ms/step - loss: 4.6022 - acc: 0.1593 - val_loss: 4.7050 - val_acc: 0.1602\n",
      "EPOCH 1 BATCH 47\n",
      "Train on 1600 samples, validate on 400 samples\n",
      "Epoch 1/1\n",
      "1600/1600 [==============================] - 45s 28ms/step - loss: 4.5782 - acc: 0.1599 - val_loss: 4.6807 - val_acc: 0.1625\n",
      "EPOCH 1 BATCH 48\n",
      "Train on 1600 samples, validate on 400 samples\n",
      "Epoch 1/1\n",
      "1600/1600 [==============================] - 45s 28ms/step - loss: 4.5511 - acc: 0.1593 - val_loss: 4.6277 - val_acc: 0.1615\n",
      "EPOCH 1 BATCH 49\n",
      "Train on 1600 samples, validate on 400 samples\n",
      "Epoch 1/1\n",
      "1600/1600 [==============================] - 45s 28ms/step - loss: 4.5737 - acc: 0.1581 - val_loss: 4.6250 - val_acc: 0.1608\n",
      "EPOCH 2 BATCH 1\n",
      "Train on 1600 samples, validate on 400 samples\n",
      "Epoch 1/1\n",
      "1600/1600 [==============================] - 45s 28ms/step - loss: 4.5471 - acc: 0.1559 - val_loss: 4.8397 - val_acc: 0.1463\n",
      "EPOCH 2 BATCH 2\n",
      "Train on 1600 samples, validate on 400 samples\n",
      "Epoch 1/1\n",
      "1600/1600 [==============================] - 45s 28ms/step - loss: 4.5370 - acc: 0.1538 - val_loss: 4.7540 - val_acc: 0.1468\n",
      "EPOCH 2 BATCH 3\n",
      "Train on 1600 samples, validate on 400 samples\n",
      "Epoch 1/1\n",
      "1600/1600 [==============================] - 45s 28ms/step - loss: 4.4857 - acc: 0.1567 - val_loss: 4.7010 - val_acc: 0.1482\n",
      "EPOCH 2 BATCH 4\n",
      "Train on 1600 samples, validate on 400 samples\n",
      "Epoch 1/1\n",
      "1600/1600 [==============================] - 45s 28ms/step - loss: 4.5066 - acc: 0.1566 - val_loss: 4.7098 - val_acc: 0.1505\n",
      "EPOCH 2 BATCH 5\n",
      "Train on 1600 samples, validate on 400 samples\n",
      "Epoch 1/1\n",
      "1600/1600 [==============================] - 45s 28ms/step - loss: 4.4971 - acc: 0.1548 - val_loss: 4.7883 - val_acc: 0.1507\n",
      "EPOCH 2 BATCH 6\n",
      "Train on 1600 samples, validate on 400 samples\n",
      "Epoch 1/1\n",
      "1600/1600 [==============================] - 45s 28ms/step - loss: 4.4918 - acc: 0.1554 - val_loss: 4.7691 - val_acc: 0.1512\n",
      "EPOCH 2 BATCH 7\n",
      "Train on 1600 samples, validate on 400 samples\n",
      "Epoch 1/1\n",
      "1600/1600 [==============================] - 45s 28ms/step - loss: 4.4926 - acc: 0.1574 - val_loss: 4.7053 - val_acc: 0.1535\n",
      "EPOCH 2 BATCH 8\n",
      "Train on 1600 samples, validate on 400 samples\n",
      "Epoch 1/1\n",
      "1600/1600 [==============================] - 45s 28ms/step - loss: 4.4773 - acc: 0.1568 - val_loss: 4.7237 - val_acc: 0.1497\n",
      "EPOCH 2 BATCH 9\n",
      "Train on 1600 samples, validate on 400 samples\n",
      "Epoch 1/1\n",
      "1600/1600 [==============================] - 44s 27ms/step - loss: 4.4450 - acc: 0.1572 - val_loss: 4.7093 - val_acc: 0.1520\n",
      "EPOCH 2 BATCH 10\n",
      "Train on 1600 samples, validate on 400 samples\n",
      "Epoch 1/1\n",
      "1600/1600 [==============================] - 45s 28ms/step - loss: 4.4714 - acc: 0.1594 - val_loss: 4.6898 - val_acc: 0.1580\n",
      "EPOCH 2 BATCH 11\n",
      "Train on 1600 samples, validate on 400 samples\n",
      "Epoch 1/1\n",
      "1600/1600 [==============================] - 46s 29ms/step - loss: 4.4864 - acc: 0.1575 - val_loss: 4.6849 - val_acc: 0.1597\n",
      "EPOCH 2 BATCH 12\n",
      "Train on 1600 samples, validate on 400 samples\n",
      "Epoch 1/1\n",
      " 864/1600 [===============>..............] - ETA: 17s - loss: 4.4304 - acc: 0.1597"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    for batch in range((num_samples//sample_per_epochs)-1):\n",
    "        print(\"EPOCH\",epoch,\"BATCH\",batch+1)fa\n",
    "        decoder_input_data=np.zeros(\n",
    "            (sample_per_epochs,ans_len,num_tokens),dtype='float32'\n",
    "        )\n",
    "        decoder_target_data=np.zeros(\n",
    "            (sample_per_epochs,ans_len,num_tokens),dtype='float32'\n",
    "        )\n",
    "        encoder_input_data=np.zeros(\n",
    "            (sample_per_epochs,que_len,num_tokens),dtype='float32'\n",
    "        )\n",
    "        for i in range(sample_per_epochs):\n",
    "            real_index=batch*sample_per_epochs+i\n",
    "            for t,word in enumerate(input_texts[real_index]):\n",
    "                encoder_input_data[i,t,token_index[word]]=1.\n",
    "            for t,word in enumerate(target_texts[real_index]):\n",
    "                decoder_input_data[i,t,token_index[word]]=1.\n",
    "                if t>0:\n",
    "                    decoder_target_data[i,t-1,token_index[word]]=1.\n",
    "        model.fit([encoder_input_data,decoder_input_data],decoder_target_data,batch_size=batch_size,epochs=1,validation_split=0.2,callbacks=[cbes])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_model = Model(encoder_inputs, encoder_states)\n",
    "\n",
    "decoder_state_input_h = Input(shape=(latent_dim,))\n",
    "decoder_state_input_c = Input(shape=(latent_dim,))\n",
    "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "decoder_outputs, state_h, state_c = decoder_lstm(\n",
    "    decoder_inputs, initial_state=decoder_states_inputs)\n",
    "decoder_states = [state_h, state_c]\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "decoder_model = Model(\n",
    "    [decoder_inputs] + decoder_states_inputs,\n",
    "    [decoder_outputs] + decoder_states)\n",
    "reverse_word_index=dict((i,char) for char,i in token_index.items())\n",
    "\n",
    "\n",
    "decoder_input_data=np.zeros(\n",
    "    (sample_per_epochs,ans_len,num_tokens),dtype='float32'\n",
    ")\n",
    "decoder_target_data=np.zeros(\n",
    "    (sample_per_epochs,ans_len,num_tokens),dtype='float32'\n",
    ")\n",
    "encoder_input_data=np.zeros(\n",
    "    (sample_per_epochs,que_len,num_tokens),dtype='float32'\n",
    ")\n",
    "for i in range(sample_per_epochs):\n",
    "    real_index=((num_samples//sample_per_epochs)-1)*sample_per_epochs+i\n",
    "    for t,word in enumerate(input_texts[real_index]):\n",
    "        encoder_input_data[i,t,token_index[word]]=1.\n",
    "    for t,word in enumerate(target_texts[real_index]):\n",
    "        decoder_input_data[i,t,token_index[word]]=1.\n",
    "        if t>0:\n",
    "            decoder_target_data[i,t-1,token_index[word]]=1.\n",
    "\n",
    "\n",
    "def decode_sequence(input_seq):\n",
    "    # Encode the input as state vectors.\n",
    "    states_value = encoder_model.predict(input_seq)\n",
    "\n",
    "    # Generate empty target sequence of length 1.\n",
    "    target_seq = np.zeros((1, 1, num_tokens))\n",
    "    # Populate the first character of target sequence with the start character.\n",
    "    target_seq[0, 0, token_index['\\t']] = 1.\n",
    "\n",
    "    # Sampling loop for a batch of sequences\n",
    "    # (to simplify, here we assume a batch of size 1).\n",
    "    stop_condition = False\n",
    "    decoded_sentence = ''\n",
    "    decoded_sequence=[]\n",
    "    while not stop_condition:\n",
    "        output_tokens, h, c = decoder_model.predict(\n",
    "            [target_seq] + states_value)\n",
    "\n",
    "        # Sample a token\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_char = reverse_word_index[sampled_token_index]\n",
    "        decoded_sentence += sampled_char\n",
    "        decoded_sequence.append(sampled_char)\n",
    "        # Exit condition: either hit max length\n",
    "        # or find stop character.\n",
    "        if (sampled_char == '\\n' or\n",
    "           len(decoded_sentence) > max_decoder_seq_length):\n",
    "            stop_condition = True\n",
    "\n",
    "        # Update the target sequence (of length 1).\n",
    "        target_seq = np.zeros((1, 1, num_tokens))\n",
    "        target_seq[0, 0, sampled_token_index] = 1.\n",
    "\n",
    "        # Update states\n",
    "        states_value = [h, c]\n",
    "\n",
    "    return decoded_sentence,decoded_sequence\n",
    "\n",
    "for seq_index in range(100):\n",
    "    # Take one sequence (part of the training set)\n",
    "    # for trying out decoding.\n",
    "    input_seq = encoder_input_data[seq_index: seq_index + 1]\n",
    "    decoded_sentence,seq = decode_sequence(input_seq)\n",
    "    print('-')\n",
    "    print('Input sentence:', input_texts[seq_index])\n",
    "    print('Decoded sentence:', decoded_sentence)\n",
    "    print('BLEU:',sentence_bleu(target_texts, seq))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "433px",
    "left": "974px",
    "right": "20px",
    "top": "120px",
    "width": "286px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
